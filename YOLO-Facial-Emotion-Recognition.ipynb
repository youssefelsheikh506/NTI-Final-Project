{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12898571,"sourceType":"datasetVersion","datasetId":8161226}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install roboflow\n!pip install ultralytics","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-28T14:06:53.458429Z","iopub.execute_input":"2025-08-28T14:06:53.459033Z","iopub.status.idle":"2025-08-28T14:08:43.301280Z","shell.execute_reply.started":"2025-08-28T14:06:53.459001Z","shell.execute_reply":"2025-08-28T14:08:43.300570Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nfrom ultralytics import YOLO\nfrom roboflow import Roboflow\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T14:21:42.035126Z","iopub.execute_input":"2025-08-28T14:21:42.035826Z","iopub.status.idle":"2025-08-28T14:21:48.470345Z","shell.execute_reply.started":"2025-08-28T14:21:42.035803Z","shell.execute_reply":"2025-08-28T14:21:48.469619Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rf = Roboflow(api_key=\"oYlcM7miU5zQhoyMjcAo\")\nproject = rf.workspace(\"youssef-elsheikh-pqoup\").project(\"facial-emotion-recognition-hnujs\")\nversion = project.version(1)\ndataset = version.download(\"yolov11\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T14:21:56.037034Z","iopub.execute_input":"2025-08-28T14:21:56.037420Z","iopub.status.idle":"2025-08-28T14:22:10.210956Z","shell.execute_reply.started":"2025-08-28T14:21:56.037399Z","shell.execute_reply":"2025-08-28T14:22:10.210207Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(dataset.location)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T14:22:12.237298Z","iopub.execute_input":"2025-08-28T14:22:12.237575Z","iopub.status.idle":"2025-08-28T14:22:12.241434Z","shell.execute_reply.started":"2025-08-28T14:22:12.237556Z","shell.execute_reply":"2025-08-28T14:22:12.240709Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"yaml_content = \"\"\"\ntest: /kaggle/working/Facial-emotion-recognition-1/test\ntrain: /kaggle/working/Facial-emotion-recognition-1/train\nval: /kaggle/working/Facial-emotion-recognition-1/valid\n\nnc: 4\nnames:\n  - angry\n  - happy\n  - sad\n  - surprised\n\"\"\"\n\nwith open('/kaggle/working/Facial-emotion-recognition-1/data1.yaml', 'w') as f:\n    f.write(yaml_content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T14:22:13.889963Z","iopub.execute_input":"2025-08-28T14:22:13.890237Z","iopub.status.idle":"2025-08-28T14:22:13.894791Z","shell.execute_reply.started":"2025-08-28T14:22:13.890217Z","shell.execute_reply":"2025-08-28T14:22:13.894063Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fine_model = YOLO('yolo11n.pt')\nnormal_model = YOLO('yolo11n.pt')\ntransfer_model = YOLO('yolo11n.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T14:22:16.459317Z","iopub.execute_input":"2025-08-28T14:22:16.459793Z","iopub.status.idle":"2025-08-28T14:22:18.414556Z","shell.execute_reply.started":"2025-08-28T14:22:16.459770Z","shell.execute_reply":"2025-08-28T14:22:18.413706Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fine_model = YOLO('fine_tuned_yolo.pt')\nnormal_model = YOLO('yolo11n.pt')\ntransfer_model = YOLO('transfer_yolo.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T16:04:13.363403Z","iopub.execute_input":"2025-08-28T16:04:13.364109Z","iopub.status.idle":"2025-08-28T16:04:13.498971Z","shell.execute_reply.started":"2025-08-28T16:04:13.364086Z","shell.execute_reply":"2025-08-28T16:04:13.498092Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fine_results = fine_model.train(data='/kaggle/working/Facial-emotion-recognition-1/data1.yaml', epochs=25, patience=5 , project='Facial Emotion Fine-tune', name='logs', device=[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T14:22:21.144013Z","iopub.execute_input":"2025-08-28T14:22:21.144557Z","iopub.status.idle":"2025-08-28T14:57:37.083513Z","shell.execute_reply.started":"2025-08-28T14:22:21.144531Z","shell.execute_reply":"2025-08-28T14:57:37.082647Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fine_model.save(\"fine_tuned_yolo.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T14:59:09.857870Z","iopub.execute_input":"2025-08-28T14:59:09.858888Z","iopub.status.idle":"2025-08-28T14:59:09.970038Z","shell.execute_reply.started":"2025-08-28T14:59:09.858852Z","shell.execute_reply":"2025-08-28T14:59:09.969444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transfer_results = transfer_model.train(data='/kaggle/working/Facial-emotion-recognition-1/data1.yaml', epochs=25 ,patience=5, project='Facial Emotion transfer', name='logs', device=[0] , freeze=\"backbone\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T15:02:54.469641Z","iopub.execute_input":"2025-08-28T15:02:54.470404Z","iopub.status.idle":"2025-08-28T15:38:07.482754Z","shell.execute_reply.started":"2025-08-28T15:02:54.470380Z","shell.execute_reply":"2025-08-28T15:38:07.481748Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transfer_model.save(\"transfer_yolo.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T15:39:04.547984Z","iopub.execute_input":"2025-08-28T15:39:04.548301Z","iopub.status.idle":"2025-08-28T15:39:04.661990Z","shell.execute_reply.started":"2025-08-28T15:39:04.548274Z","shell.execute_reply":"2025-08-28T15:39:04.661364Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\n\n# Load images\nimg_fine = cv2.imread(\"/kaggle/working/Facial Emotion Fine-tune/logs/results.png\")\nimg_transfer = cv2.imread(\"/kaggle/working/Facial Emotion transfer/logs2/results.png\")\n\n# Convert BGR to RGB\nimg_fine = cv2.cvtColor(img_fine, cv2.COLOR_BGR2RGB)\nimg_transfer = cv2.cvtColor(img_transfer, cv2.COLOR_BGR2RGB)\n\n# Create side-by-side plot\nplt.figure(figsize=(14,6))  # width x height\n\nplt.subplot(1, 2, 1)  # 1 row, 2 columns, first plot\nplt.imshow(img_fine)\nplt.axis(\"off\")\nplt.title(\"Fine-tuned YOLO\")\n\nplt.subplot(1, 2, 2)  # 1 row, 2 columns, second plot\nplt.imshow(img_transfer)\nplt.axis(\"off\")\nplt.title(\"Transfer-learned YOLO\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T15:42:35.379601Z","iopub.execute_input":"2025-08-28T15:42:35.380218Z","iopub.status.idle":"2025-08-28T15:42:36.363591Z","shell.execute_reply.started":"2025-08-28T15:42:35.380193Z","shell.execute_reply":"2025-08-28T15:42:36.362623Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load CSVs and titles\ndfs = [\n    (\"/kaggle/working/Facial Emotion Fine-tune/logs/results.csv\", \"Fine-tuned YOLO\"),\n    (\"/kaggle/working/Facial Emotion transfer/logs2/results.csv\", \"Transfer-learned YOLO\")\n]\n\n# Loss types\nlosses = [\"box\", \"cls\", \"dfl\"]\n\nplt.figure(figsize=(18, 5))\n\nfor idx, loss in enumerate(losses, 1):\n    plt.subplot(1, 3, idx)\n\n    for path, title in dfs:\n        df = pd.read_csv(path)\n\n        # Training loss\n        col_train = f\"train/{loss}_loss\"\n        plt.plot(df[\"epoch\"], df[col_train], label=f\"{title} Train\")\n\n        # Validation loss\n        col_val = f\"val/{loss}_loss\"\n        if col_val in df.columns:\n            plt.plot(df[\"epoch\"], df[col_val], linestyle=\"--\", label=f\"{title} Val\")\n\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(f\"{loss.upper()} Loss\")\n    plt.title(f\"{loss.upper()} Loss Comparison\")\n    plt.legend()\n    plt.grid(True)\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T15:54:40.019239Z","iopub.execute_input":"2025-08-28T15:54:40.019564Z","iopub.status.idle":"2025-08-28T15:54:40.824922Z","shell.execute_reply.started":"2025-08-28T15:54:40.019544Z","shell.execute_reply":"2025-08-28T15:54:40.823862Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate Fine-Tune model\nfine_test = fine_model.val(data='/kaggle/working/Facial-emotion-recognition-1/data1.yaml', split=\"test\")\n\n# Evaluate original model\nnormal_test = normal_model.val(data='/kaggle/working/Facial-emotion-recognition-1/data1.yaml', split=\"test\")\n\n# Evaluate Transfer model\ntransfer_test = transfer_model.val(data='/kaggle/working/Facial-emotion-recognition-1/data1.yaml', split=\"test\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T15:44:14.238370Z","iopub.execute_input":"2025-08-28T15:44:14.239125Z","iopub.status.idle":"2025-08-28T15:44:39.700985Z","shell.execute_reply.started":"2025-08-28T15:44:14.239099Z","shell.execute_reply":"2025-08-28T15:44:39.700222Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extract main metrics from a YOLOv11 DetMetrics object\ndef extract_metrics(result):\n    # mean_results() returns precision, recall, mAP50, mAP50-95\n    precision, recall, mAP50, mAP5095 = result.mean_results()\n    return precision, recall, mAP50, mAP5095\n\n# Fine-tuned model\nfine_prec, fine_rec, fine_mAP50, fine_mAP5095 = extract_metrics(fine_test)\n\n# Original model\nnorm_prec, norm_rec, norm_mAP50, norm_mAP5095 = extract_metrics(normal_test)\n\n# Transfer-learned model\ntrans_prec, trans_rec, trans_mAP50, trans_mAP5095 = extract_metrics(transfer_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T15:44:43.644905Z","iopub.execute_input":"2025-08-28T15:44:43.645229Z","iopub.status.idle":"2025-08-28T15:44:43.650925Z","shell.execute_reply.started":"2025-08-28T15:44:43.645201Z","shell.execute_reply":"2025-08-28T15:44:43.650306Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nmodels = [\"Fine-tuned YOLO\", \"Original YOLO\", \"Transfer-learned YOLO\"]\nmAP50 = [fine_mAP50, norm_mAP50, trans_mAP50]\nmAP5095 = [fine_mAP5095, norm_mAP5095, trans_mAP5095]\n\nx = range(len(models))\nwidth = 0.20\n\nplt.figure(figsize=(8,5))\nplt.bar(x, mAP50, width=width, label=\"mAP@0.5\")\nplt.bar([i + width for i in x], mAP5095, width=width, label=\"mAP@0.5:0.95\")\nplt.xticks([i + width/2 for i in x], models, rotation=15)\nplt.ylabel(\"mAP\")\nplt.title(\"Model Comparison on Test Set\")\nplt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.grid(axis=\"y\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T15:44:46.491777Z","iopub.execute_input":"2025-08-28T15:44:46.492085Z","iopub.status.idle":"2025-08-28T15:44:46.656843Z","shell.execute_reply.started":"2025-08-28T15:44:46.492065Z","shell.execute_reply":"2025-08-28T15:44:46.656197Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nimport os\nimport random\n\n# Folder containing test images\ntest_folder = \"/kaggle/working/Facial-emotion-recognition-1/test/images\"\nall_images = [os.path.join(test_folder, f) for f in os.listdir(test_folder) if f.endswith((\".jpg\", \".png\"))]\n\n# Pick 1 random image\nimg_path = random.choice(all_images)\n\n# Models\nmodels = [\n    (fine_model, \"Fine-tuned YOLO\"),\n    (normal_model, \"Original YOLO\"),\n    (transfer_model, \"Transfer-learned YOLO\")\n]\n\n# Plot\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\nfig.suptitle(\"Predictions of 3 Models on One Random Test Image\", fontsize=16)\n\nfor i, (model, model_name) in enumerate(models):\n    # Run prediction\n    results = model.predict(img_path)\n    pred_img = results[0].plot()  # prediction with boxes\n\n    # Plot\n    axes[i].imshow(pred_img)\n    axes[i].axis(\"off\")\n    axes[i].set_title(model_name, fontsize=12)\n\nplt.tight_layout()\nplt.subplots_adjust(top=0.85)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T16:04:19.237822Z","iopub.execute_input":"2025-08-28T16:04:19.238720Z","iopub.status.idle":"2025-08-28T16:04:20.064675Z","shell.execute_reply.started":"2025-08-28T16:04:19.238682Z","shell.execute_reply":"2025-08-28T16:04:20.063991Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load CSVs and titles\ndfs = [\n    (\"/kaggle/input/10-epochs/fine_results.csv\", \"Fine-tuned YOLO\"),\n    (\"/kaggle/input/10-epochs/transfer_results.csv\", \"Transfer-learned YOLO\")\n]\n\n# Loss types\nlosses = [\"box\", \"cls\", \"dfl\"]\n\nplt.figure(figsize=(18, 5))\n\nfor idx, loss in enumerate(losses, 1):\n    plt.subplot(1, 3, idx)\n\n    for path, title in dfs:\n        df = pd.read_csv(path)\n\n        # Training loss\n        col_train = f\"train/{loss}_loss\"\n        plt.plot(df[\"epoch\"], df[col_train], label=f\"{title} Train\")\n\n        # Validation loss\n        col_val = f\"val/{loss}_loss\"\n        if col_val in df.columns:\n            plt.plot(df[\"epoch\"], df[col_val], linestyle=\"--\", label=f\"{title} Val\")\n\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(f\"{loss.upper()} Loss\")\n    plt.title(f\"{loss.upper()} Loss Comparison\")\n    plt.legend()\n    plt.grid(True)\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T17:04:12.807297Z","iopub.execute_input":"2025-08-28T17:04:12.807597Z","iopub.status.idle":"2025-08-28T17:04:13.607333Z","shell.execute_reply.started":"2025-08-28T17:04:12.807576Z","shell.execute_reply":"2025-08-28T17:04:13.606226Z"}},"outputs":[],"execution_count":null}]}